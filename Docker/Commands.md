# Docker

Run your application always inside the same environment.

The difference between virtual machine and docker is that the apps in docker shares the kernel that docker provides, which unluckily shares some functionalities with the host (that's why mac-m1 sometimes doesn't work with some python package that works in ubuntu) while virtual machines install everything inside the host.

Docker run a container from an image. To run a container we need an image.

## installation on arch linux

Installation guide to not executing docker with sudo every time

``` bash
sudo groupadd --system docker
sudo useradd -m -g $USER docker
sudo usermod -aG docker $USER # or sudo usermod -a -G docker ${USER}
newgrp docker
sudo snap install docker
```

## TCP not working
``` bash
# try this
sudo snap disable docker
sudo snap enable docker
# or this
sudo snap refresh docker --edge
```

# Image

The image is conformed by
- Has the Operative system (not the kernel).
- Has our software and tis dependencies.

Image are generated by Dockerfile

Docker build to generate the image from our dockerfile and docker run for run it in a container.

The image can be created by us or by other person.

# Run Image

``` bash
docker run postgress
```
If the image is not found local, it's going to look it in the docker hub.

You can download the image without executing it with
``` bash
docker pull postgress
```

We can add a tag at the end, where it differenciate different versions, default is `latest`

``` bash
docker run postgress:version
```

Sometimes it will ask you to run with environment variables like this

``` bash
docker run -e PASSWORD=password postgress:version
```

Each image is a set of layers, so when you download it, it will download every layer asociated with different hashes. This allow you to download only the layers that you don't have in your machine.

# Useful commands

Shows all your images
``` bash
docker images # | head -> for just show some of them 
```

Show which containers are running

``` bash
docker ps
```

Show all containers running and not running

``` bash
docker ps -a
```

Run containers that are stopped, all the data will be again alive. But the idea of the containers is not to save data in the container.

``` bash
docker start <container id>
```

Show the logs of a ontainer

``` bash
docker logs <container id> # We can also specify by name instead of container ID. 
```

If you want to follow the log and keep showing you

``` bash
docker logs -f <container id>
```

NEVER send the logs in a file inside the docker container, because docker captures the stdout of the app and can show it to you.

Execute a command inside a docker that is running

``` bash
docker exec -it <container id> sh # i creates an interactive session and t it's going to emulate a terminal, and we can execute sh which is a shell so we can execute other commands in the shell.
```

Stop the container

``` bash
docker stop <container id>
```

Run container in background mode

``` bash
docker run -d <container id> # where d means detach.
```

Check memory and CPU usages:

``` bash
docker stats --no-stream
docker stats --no-stream -a # all containers
```

Status of your container
``` bash
docker stats
```

# Dockerfile

``` bash
FROM ... # parent image

WORKDIR /app # directoy created automaically and all commands are going to be executed here

COPY . . # copy everything that I have in my application into /app

RUN yarn install --production # compile our code and dependencies

CMD["node", "/app/src/index.js"] # once everything is build this is the command that will be executed

# there is one more sometimes ENTRYPOINTS that allows users to set a command that later they will be give the arguments.

```
## tags

The tags related to the next names
- alpine: distro created for containers (but lastly developers are not using it any more because are hard to debug)
- buster: 
- stretch

These are distributions of linux that owners used to create the images

It's always a good practice to put the tag because if not your code maybe will be incopatible in the future becase your image dependency will be updated automatically.

## Build

Docker build with a tag
``` bash
docker build -t <tag> . # dont forget the last point to point the Dockerfile in the current folder
```


# Advance Run Commands 
Check out that once you run a docker, it shows you which port is listening to so you can navigate and see the content of that website.

But if you go to localhost:3000 , you will see connection refuse because the docker container is not sharing anything with the externa world. If we want to access to that port3000 we have to specify it in the line of docker run.

``` bash
docker run -p 3000:3000 <tag> .
docker run -d -p 3000:3000 <tag> . # to detach
docker run -dp 3000:3000 <tag> . # for both -d and -p
```

Now we are going to expose the port 3000 to the compute network

## Start

If you want to stop and persist data you have to start the container you stopped, not run a new one.

``` bash
docker start <docker id>
```

If you want to share things with your computer and persist in YOUR computer:

``` bash
docker run -v <origin route of what we want to put inside the docker>
docker run -v /Users/kbs/ejemplo-docker/app/etc:/etc/todos -p 3000:3000 -d getting-started
```
where `/Users/kbs/ejemplo-docker/app` is your working directory
and `/etc/todos` the directory of the db. the `:<folder>` I don't know what is for but it's necessary to connect between both things.
``` bash
ls
response -> etc/todos.db
```
That was created automatically when you inited the container.
This volum is bidirectional, which means if you modify it from outside, the code inside the container will see the changes.

## Link the code of the docker from oustide the container

``` bash
docker run -d -v /Users/kbs/ejemplo-docker/app/etc:/etc/todos -p 3000:3000 -v /Users/kbs/ejemplo-docker/app/src:/app/src getting-started
```

So if you now change the files in your `src` folder will be changes inside the container also because it's bidirectional.

# Docker hub

They give you free hosting only if they are public. For private you have to pay.

You have to tag very correctly the tag. So, if you are going to push something

``` bash
docker tag <image ID> username/name:v2  # I want to tag the image ID with that long name
```

Now if you do docker image you will see two equal image with distinct names unless we have named correctly from the beginning.

# Resources

[pelado nerd](https://www.youtube.com/watch?v=CV_Uf3Dq-EU&t=1327s)

# Docker-compose

Continue watching the video.

``` bash
dcoker login

```

# Process to build docker and push in GCP Cloud Shell 

``` bash
docker build -t gcr.io/eighth-effect-136722/name-completer-app .
docker images -> to get image ID: bbdcdcba6456
docker tag bbdcdcba6456 gcr.io/eighth-effect-136722/name-completer-app:v1.2
docker push gcr.io/eighth-effect-136722/name-completer-app:v1.2
```
